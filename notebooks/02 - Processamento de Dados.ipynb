{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processamento de Dados\n",
    "\n",
    "Como segunda etapa do projeto, é preciso tratar os dados **antes** de os mesmos serem utilizados em um modelo de aprendizado de máquina. Todas as transformações testadas e aplicadas serão vistas neste Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pacotes e Inicialização Importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# usado para o valor float do Pandas ficar neste formato\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura dos dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inadimplente</th>\n",
       "      <th>util_linhas_inseguras</th>\n",
       "      <th>idade</th>\n",
       "      <th>vezes_passou_de_30_59_dias</th>\n",
       "      <th>razao_debito</th>\n",
       "      <th>salario_mensal</th>\n",
       "      <th>numero_linhas_crdto_aberto</th>\n",
       "      <th>numero_vezes_passou_90_dias</th>\n",
       "      <th>numero_emprestimos_imobiliarios</th>\n",
       "      <th>numero_de_vezes_que_passou_60_89_dias</th>\n",
       "      <th>numero_de_dependentes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.77</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>9,120.00</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2,600.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.09</td>\n",
       "      <td>3,042.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>3,300.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>63,588.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inadimplente  util_linhas_inseguras  idade  vezes_passou_de_30_59_dias  \\\n",
       "0             1                   0.77     45                           2   \n",
       "1             0                   0.96     40                           0   \n",
       "2             0                   0.66     38                           1   \n",
       "3             0                   0.23     30                           0   \n",
       "4             0                   0.91     49                           1   \n",
       "\n",
       "   razao_debito  salario_mensal  numero_linhas_crdto_aberto  \\\n",
       "0          0.80        9,120.00                          13   \n",
       "1          0.12        2,600.00                           4   \n",
       "2          0.09        3,042.00                           2   \n",
       "3          0.04        3,300.00                           5   \n",
       "4          0.02       63,588.00                           7   \n",
       "\n",
       "   numero_vezes_passou_90_dias  numero_emprestimos_imobiliarios  \\\n",
       "0                            0                                6   \n",
       "1                            0                                0   \n",
       "2                            1                                0   \n",
       "3                            0                                0   \n",
       "4                            0                                1   \n",
       "\n",
       "   numero_de_vezes_que_passou_60_89_dias  numero_de_dependentes  \n",
       "0                                      0                   2.00  \n",
       "1                                      0                   1.00  \n",
       "2                                      0                   0.00  \n",
       "3                                      0                   0.00  \n",
       "4                                      0                   0.00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = '../data/raw/treino.csv'\n",
    "\n",
    "df = pd.read_csv(train_path, sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento de valores faltantes\n",
    "\n",
    "Apenas duas colunas dos dados se encontram com valores faltantes. Como será testado algumas maneiras de formatar tais dados, por enquanto, podemos simplesmente preenche-los com $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divisão dos Dados\n",
    "\n",
    "Antes de trabalhar com o processamento dos dados, é necessário fazer duas etapas:\n",
    "\n",
    "* Organizar os Dados em X e y - É preciso ter separado as Entradas e Saídas do modelo, que neste caso chamaremos de X e y, respectivamente.\n",
    "* Treino e Teste - Para podermos avaliar se o processamento dos dados teve resultados positivos, será necessário dividir a informação em dois grupos: treino e teste, onde a primeira é usada para treinar os modelos com os dados processados, e a segunda irá avaliar os seus desempenhos em dados não vistos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividindo em X e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['inadimplente'])\n",
    "y = df['inadimplente']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do X: (110000, 10)\n",
      "Shape do y: (110000,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape do X:', X.shape) # 10 Features\n",
    "print('Shape do y:', y.shape) # 1 target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treino e Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazer tal divisão, será utilizado a função `train_test_split` da biblioteca **sklearn**. Os dados serão dividos na seguinte proporção: 80% de Treino e 20% de Teste. Para não ocorrer nenhum vazamento de informação, estes dados só serão avaliados com o **melhor modelo encontrado**. Como a quantidade de dados positivos é baixa, será trabalhado com a técnica de validação cruzada para obter os resultados dos modelos.\n",
    "\n",
    "**A divisão foi feita utilizando o argumento stratify, que garante que a distribuição dos exemplos continue a mesma entre treino e teste**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    82135\n",
       "1     5865\n",
       "Name: inadimplente, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts() # Quantidade de dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20534\n",
       "1     1466\n",
       "Name: inadimplente, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts() # Quantidade de dados de Treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste Inicial\n",
    "\n",
    "Para se ter uma visão inicial dos dados, será feito um treinamento dos dados em 3 modelos diferentes: \n",
    "\n",
    "* Árvores de Decisão\n",
    "* Random Forest\n",
    "* XGBoost\n",
    "\n",
    "Neste primeiro teste, será utilizado os dados \"crus\", apenas modificando os valores nulos para **ZERO**. Com isso, é possível ter uma estimativa base do desempenho desses dados nos modelos e o que precisa ser batido para termos um resultado melhor. Para isso, será utilizado o a função `cross_val_score` que retorna o resultados de uma certa métrica na validação cruzada. Nestes testes será escolhido um total de 7 *Folds* para validação, permitindo que sejam feitos 7 testes com uma divisão próxima de [85% teste e 15% validação]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos a serem treinados irão utilizar o balanceamento dos pesos, para que todas as classes tenham a mesma importância. Para verificar o desempenho, será avaliado a métrica de *F1-Score*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, será testado uma Árvore de Decisão, pois é um dos modelos mais simples e rápidos de ser treinado, e já é possível ter uma pequena noção do que esperar como resultado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árvore de Decisão\n",
      "F1-Score médio em 7 folds: 0.255\n",
      "Desvio Padrão do F1 em 7 folds: 0.009\n",
      "[0.26161369 0.27010436 0.24317618 0.24479495 0.25197809 0.25684723\n",
      " 0.25364078]\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=0, class_weight='balanced')\n",
    "results = cross_val_score(dtc, X_train, y_train, \n",
    "                          cv=7, scoring='f1', n_jobs=-1)\n",
    "\n",
    "print('Árvore de Decisão')\n",
    "print('F1-Score médio em 7 folds: {:.3f}'.format(np.mean(results)))\n",
    "print('Desvio Padrão do F1 em 7 folds: {:.3f}'.format(np.std(results)))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em segundo, passaremos pelas Random Forest. Elas funcionam da mesma maneira que as árvores de decisão, mas utilizando várias \"árvóres\" geradas aleatóriamente. Assim, é possível ter um modelo mais generalista ao problema que (provavelmente) terá um resultado melhor que o anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "F1-Score médio em 5 folds: 0.221\n",
      "Desvio Padrão do F1 em 7 folds: 0.008\n",
      "[0.21002838 0.21910112 0.2245283  0.21374046 0.22867854 0.23330198\n",
      " 0.21821632]\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=0, class_weight='balanced')\n",
    "results = cross_val_score(rfc, X_train, y_train, \n",
    "                          cv=7, scoring='f1', n_jobs=-1)\n",
    "\n",
    "print('Random Forest')\n",
    "print('F1-Score médio em 5 folds: {:.3f}'.format(np.mean(results)))\n",
    "print('Desvio Padrão do F1 em 7 folds: {:.3f}'.format(np.std(results)))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.004262574595055"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()[0] / y_train.value_counts()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, será usado o modelo que é o estado da arte em dados tabulares. O XGBoost também trabalha com árvores de decisão, mas utilizando o agrupamento de diversas árvores para obter o melhor resultado possível através da união de seus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "F1-Score médio em 5 folds: 0.331\n",
      "Desvio Padrão do F1 em 7 folds: 0.006\n",
      "[0.32664465 0.32329317 0.32622656 0.34278416 0.33325006 0.33501769\n",
      " 0.32756867]\n"
     ]
    }
   ],
   "source": [
    "# o balanceamento no XGBoost pode ser calculado\n",
    "# através da formula: (exemplos negativos) / (exemplos positivos)\n",
    "n = y_train.value_counts()[0]\n",
    "p = y_train.value_counts()[1]\n",
    "weight = n / p\n",
    "\n",
    "xgb = XGBClassifier(random_state=0, scale_pos_weight=weight)\n",
    "results = cross_val_score(xgb, X_train, y_train, \n",
    "                          cv=7, scoring='f1', n_jobs=-1)\n",
    "\n",
    "print('XGBoost')\n",
    "print('F1-Score médio em 5 folds: {:.3f}'.format(np.mean(results)))\n",
    "print('Desvio Padrão do F1 em 7 folds: {:.3f}'.format(np.std(results)))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento das variáveis\n",
    "\n",
    "Através dos *insights* retirados da Análise feita anteriormente, é proposto algumas modificações a serem feitas nos dados para tentar obter um melhor resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `idade`\n",
    "\n",
    "A variável **idade** possuí poucos valores *outliers* e variando de maneira natural. Esses *outliers* são idades como ZERO e as próximas do 100 anos. É possível que não seja preciso fazer nenhuma mudança, mas para tentar contornar tal problema (se houver), será utilizando a inclusão da **FAIXA ETÁRIA ANS**. A faixa etária ANS é dividida da seguinte maneira:\n",
    "\n",
    "* a) 0 a 18 anos \n",
    "* b) 19 a 23 anos\n",
    "* c) 24 a 28 anos\n",
    "* d) 29 a 33 anos\n",
    "* e) 34 a 38 anos\n",
    "* f) 39 a 43 anos\n",
    "* g) 44 a 48 anos\n",
    "* h) 49 a 53 anos\n",
    "* i) 54 a 58 anos\n",
    "* j) 59 anos ou mais.\n",
    "\n",
    "Além de possuir menos valores possíveis, eles ainda contém **ordem**, o que permite que sejam agrupados em valores sequências. Neste caso, de 1 até 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "faixa_etaria_ans = [18, 23, 28, \n",
    "                    33, 38, 43, \n",
    "                    48, 53, 58,]\n",
    "\n",
    "def get_faixa_etaria(idade):\n",
    "    \n",
    "    for i, f in enumerate(faixa_etaria_ans, 1):\n",
    "        if idade <= f:\n",
    "            return i\n",
    "    else:\n",
    "        return i + 1\n",
    "\n",
    "def add_faixa_etaria(data):\n",
    "    \n",
    "    data['faixa_etaria'] = data['idade'].apply(get_faixa_etaria)\n",
    "    data.drop(columns=['idade'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `numero_de_dependentes`\n",
    "\n",
    "A maioria dos dados possuí poucos dependentes, enquantos poucos valores possuem uma grande quantidade. Neste caso, é proposto o agrupamento desses dados nos seguintes grupos:\n",
    "\n",
    "* 0 -> Sem dependentes\n",
    "* 1 -> Um dependente\n",
    "* 2 -> Dois dependentes\n",
    "* 3 -> Três ou Quatro dependentes\n",
    "* 4 -> Cinco ou mais dependentes\n",
    "\n",
    "Assim como a idade, este grupo possui **ordem**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupo_dependentes = [0, 1, 2, 4]\n",
    "\n",
    "def get_grupo_dependentes(n):\n",
    "    \n",
    "    for i, g in enumerate(grupo_dependentes):\n",
    "        if n <= g:\n",
    "            return i\n",
    "    else:\n",
    "        return i+1\n",
    "\n",
    "def add_grupo_dependentes(data):\n",
    "    \n",
    "    r = data['numero_de_dependentes'].apply(get_grupo_dependentes)\n",
    "    data['grupo_dependentes'] = r\n",
    "    \n",
    "    data.drop(columns=['numero_de_dependentes'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `numero_emprestimos_imobiliarios`\n",
    "\n",
    "A esmagadora maioria dos dados estão entre o intervalo de 0 até 2, as outras quantidades encontradas estão distribuídas em quantidades pequenas. A solução aplicada para esta variável é deixar como o maior limite em 3, onde qualquer valor acima disso é modificado para 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_grupo_imobiliario(data):\n",
    "    \n",
    "    index = (data['numero_emprestimos_imobiliarios'] > 3)\n",
    "    col = 'numero_emprestimos_imobiliarios'\n",
    "    \n",
    "    data.loc[index, col] = 3\n",
    "    data.rename(columns={\n",
    "        'numero_emprestimos_imobiliarios': 'grupo_imobiliario'\n",
    "    }, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `util_linhas_inseguras`\n",
    "\n",
    "Como foi mostrado na análise de dados, a partir do número 2 os valores começam a se distribuir em intervalos bem grandes. A solução aplicada para esta coluna é a mesma da anterior, limitar sua quantidade em 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_util_linhas_inseguras(data):\n",
    "    \n",
    "    index = (data['util_linhas_inseguras'] > 2.0)\n",
    "    col = 'util_linhas_inseguras'\n",
    "    \n",
    "    data.loc[index, col] = 2.0\n",
    "    data.rename(columns={\n",
    "        'util_linhas_inseguras': 'util_linhas_inseguras_limitada'\n",
    "    }, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `salario_mensal`\n",
    "\n",
    "Como os salários variam bastante no conjunto de dados, foi decidido agrupar eles em grupos, para não ter que tratar com grandes quantidades e valores tão diferentes. Os grupos decididos foram os seguintes:\n",
    "\n",
    "| Grupo | Descrição |\n",
    "| - | :- |\n",
    "| 0 | Sem salário definido ou 0 |\n",
    "| 1 | Até 2 Salários Mínimos |\n",
    "| 2 | Entre 2 e 4 Salários Mínimos |\n",
    "| 3 | Entre 4 e 10 Salários Mínimos |\n",
    "| 4 | Entre 10 e 20 Salários Mínimos |\n",
    "| 5 | Mais de 20 Salários Mínimos |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "salario_minimo =  1_100\n",
    "grupo_salarial = [2, 4, 10, 20]\n",
    "\n",
    "def get_grupo_salarial(n):\n",
    "    \n",
    "    if (n == np.nan) or (n == 0):\n",
    "        return 0\n",
    "    \n",
    "    for i, g in enumerate(grupo_salarial, 1):\n",
    "        if n <= g * salario_minimo:\n",
    "            return i\n",
    "    else:\n",
    "        return i+1\n",
    "\n",
    "def add_grupo_salarial(data):\n",
    "    \n",
    "    r = data['salario_mensal'].apply(get_grupo_salarial)\n",
    "    data['grupo_salarial'] = r\n",
    "    \n",
    "    data.drop(columns=['salario_mensal'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `vezes_passou_X_dias`\n",
    "\n",
    "Existe 3 variáveis com o mesmo sentido, apenas modificando a quantidade de dias que teve de atraso. Elas são as seguintes:\n",
    "\n",
    "* **`vezes_passou_de_30_59_dias`**\n",
    "* **`numero_de_vezes_que_passou_60_89_dias`**\n",
    "* **`numero_vezes_passou_90_dias`**\n",
    "\n",
    "A mudança a ser feita é a seguinte: não será mais contado a quantidade de vezes que a pessoa passou, apenas se ela passou alguma vez ou não. Com isso, cada uma das colunas indicaria se atrasou alguma vez em cada um dos intervalos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_atraso_em_meses(data):\n",
    "    \n",
    "    columns = [\n",
    "        'vezes_passou_de_30_59_dias',\n",
    "        'numero_de_vezes_que_passou_60_89_dias',\n",
    "        'numero_vezes_passou_90_dias',\n",
    "    ]\n",
    "    \n",
    "    for v, col in enumerate(columns, 1):\n",
    "        \n",
    "        index = (data[col] > 0)\n",
    "        data.loc[index, col] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `razao_debito`\n",
    "\n",
    "Razão débito possui um comportamento parecido com `util_linhas_inseguras`, mas tendo uma parcela maior fora do intervalo de 0 até 1. Mesmo assim, será utilizado a mesma técnica que na variável anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_razao_debito(data):\n",
    "    \n",
    "    index = (data['razao_debito'] > 2.0)\n",
    "    col = 'razao_debito'\n",
    "    \n",
    "    data.loc[index, col] = 2.0\n",
    "    data.rename(columns={\n",
    "        'razao_debito': 'razao_debito_limitada'\n",
    "    }, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliando os diferentes tratamentos\n",
    "\n",
    "Como não sabemos se tais mudanças terão um bom desempenho na solução do problema, uma possível estratégia é o teste de todas as combinações de tratamentos possíveis, para decidir quais entregam os melhores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamentos propostos\n",
    "methods = [\n",
    "    add_faixa_etaria,\n",
    "    add_grupo_dependentes,\n",
    "    limit_util_linhas_inseguras,\n",
    "    add_grupo_salarial,\n",
    "    add_atraso_em_meses,\n",
    "    limit_razao_debito,\n",
    "]\n",
    "\n",
    "# Aplica os métodos no dataset passado\n",
    "def fix_data(X, y, methods):\n",
    "    X_new = X.copy()\n",
    "    y_new = y.copy()\n",
    "    \n",
    "    for m in methods:\n",
    "        m(X_new)\n",
    "    \n",
    "    y_new = y_new[y_new.index.isin(X_new.index)]\n",
    "    return X_new, y_new\n",
    "\n",
    "\n",
    "# Avalia os dados com uma combinação de métodos.\n",
    "def test_method(X, y, methods):\n",
    "    \n",
    "    X_new, y_new = fix_data(X, y, methods)\n",
    "    xgb = XGBClassifier(random_state=0, scale_pos_weight=weight)\n",
    "    results = cross_val_score(xgb, X_new, y_new, \n",
    "                              cv=7, scoring='f1', n_jobs=-1)\n",
    "    \n",
    "    return results\n",
    "    \n",
    "\n",
    "# Testa todas as combinações possíveis de métodos\n",
    "def test_methods_combinations(X, y):\n",
    "    \n",
    "    # Adiciona todas combinações\n",
    "    combinations = []\n",
    "    for s in range(0, len(methods)+1):\n",
    "        combinations += [c for c in itertools.combinations(methods, s)]\n",
    "    \n",
    "    # Itera sobre todas as combinações\n",
    "    results = []\n",
    "    for i, c in enumerate(combinations, 1):\n",
    "        print('\\r[{}/{}]'.format(i, len(combinations)), end='')\n",
    "        \n",
    "        # Testa a combinação e recebe os resultados de F1-Score\n",
    "        c = list(c)\n",
    "        r = test_method(X, y, c)\n",
    "        \n",
    "        # Pega os nomes das funções\n",
    "        c = [f.__name__ for f in c]\n",
    "        \n",
    "        # Registro do teste\n",
    "        data = {\n",
    "            'methods': c, # Lista de métodos\n",
    "            'f1_mean': np.mean(r), # Média dos F1-Score\n",
    "            'f1_std': np.std(r), # Desvio Padrão do F1-Score\n",
    "        }\n",
    "        \n",
    "        results += [data]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64/64]"
     ]
    }
   ],
   "source": [
    "results = test_methods_combinations(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os resultados adquiridos, é possível ordenar esta informação para termos a melhor combinação possível em primeiro (maior F1-Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort(key=lambda x: x['f1_mean'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E agora, visualizaremos esta informação em formatado de `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>methods</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[add_faixa_etaria, add_grupo_dependentes]</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[add_faixa_etaria, add_grupo_dependentes, limi...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[add_faixa_etaria]</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[add_faixa_etaria, add_grupo_dependentes, limi...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[add_faixa_etaria, limit_util_linhas_inseguras...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>[add_grupo_salarial, add_atraso_em_meses, limi...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>[add_faixa_etaria, add_grupo_dependentes, add_...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>[limit_util_linhas_inseguras, add_grupo_salari...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>[add_grupo_dependentes, limit_util_linhas_inse...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>[add_faixa_etaria, add_grupo_dependentes, limi...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              methods  f1_mean  f1_std\n",
       "0           [add_faixa_etaria, add_grupo_dependentes]     0.33    0.01\n",
       "1   [add_faixa_etaria, add_grupo_dependentes, limi...     0.33    0.01\n",
       "2                                  [add_faixa_etaria]     0.33    0.01\n",
       "3   [add_faixa_etaria, add_grupo_dependentes, limi...     0.33    0.01\n",
       "4   [add_faixa_etaria, limit_util_linhas_inseguras...     0.33    0.01\n",
       "..                                                ...      ...     ...\n",
       "59  [add_grupo_salarial, add_atraso_em_meses, limi...     0.33    0.01\n",
       "60  [add_faixa_etaria, add_grupo_dependentes, add_...     0.33    0.01\n",
       "61  [limit_util_linhas_inseguras, add_grupo_salari...     0.33    0.01\n",
       "62  [add_grupo_dependentes, limit_util_linhas_inse...     0.33    0.01\n",
       "63  [add_faixa_etaria, add_grupo_dependentes, limi...     0.33    0.01\n",
       "\n",
       "[64 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = pd.DataFrame(results)\n",
    "\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que todas as 64 combinações tiveram a mesma média de F1-Score (se arredondar os dados para duas casas decimais). Apenas por descaso de consciência, veremos como o desvio padrão se distribuí (quanto menor o desvio, menor a variação do resultado)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   64.00\n",
       "mean     0.01\n",
       "std      0.00\n",
       "min      0.00\n",
       "25%      0.01\n",
       "50%      0.01\n",
       "75%      0.01\n",
       "max      0.01\n",
       "Name: f1_std, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['f1_std'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pela distribuição, é possível ver que o menor está como zero. Isso apenas significa que o arredondamento o fez chegar neste valor. Veremos quais métodos foram usados para encontrar tal resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['add_faixa_etaria',\n",
       " 'add_grupo_dependentes',\n",
       " 'limit_util_linhas_inseguras',\n",
       " 'add_grupo_salarial',\n",
       " 'limit_razao_debito']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.sort_values('f1_std', ascending=False)['methods'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando os dados para treinamento\n",
    "\n",
    "Com os melhores métodos encontrados, podemos tratar os dados e salva-los para utilização no Notebook final que fará a predição da probabilidade dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados Tratados\n",
    "\n",
    "Primeiramente, será salvado os dados com os tratamentos que obtiveram o menor desvio padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métodos que tiveram o menor desvio padrão\n",
    "best_methods = [\n",
    "    add_faixa_etaria,\n",
    "    add_grupo_dependentes,\n",
    "    limit_util_linhas_inseguras,\n",
    "    add_grupo_salarial,\n",
    "    limit_razao_debito,\n",
    "]\n",
    "\n",
    "# Dados de Treinamento processado\n",
    "X_train_processed, y_train_processed = fix_data(\n",
    "    X_train, y_train, best_methods)\n",
    "\n",
    "# Dados de Teste processado\n",
    "X_test_processed, y_test_processed = fix_data(\n",
    "    X_test, y_test, best_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizando o treinamento em apenas um dataframe\n",
    "train_processed = X_train_processed.copy()\n",
    "train_processed['inadimplente'] = y_train_processed.values\n",
    "\n",
    "# Organizando o teste em apenas um dataframe\n",
    "test_processed = X_test_processed.copy()\n",
    "test_processed['inadimplente'] = y_test_processed.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os dados de treino processado\n",
    "train_processed.to_csv('../data/processed/train_processed.csv', \n",
    "                       sep=',', index=False)\n",
    "\n",
    "# Salvando os dados de teste (Neste caso, será chamado \n",
    "# como dev, pra não ter engano com os dados de teste final)\n",
    "test_processed.to_csv('../data/processed/dev_processed.csv', \n",
    "                      sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados \"Sem Processamento\"\n",
    "\n",
    "Para finalizar, os dados são salvados sem nenhum tratamento apresentado **apenas a adição de ZERO nos dados faltantes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizando o treinamento em apenas um dataframe\n",
    "train = X_train.copy()\n",
    "train['inadimplente'] = y_train.values\n",
    "\n",
    "# Organizando o teste em apenas um dataframe\n",
    "test = X_test.copy()\n",
    "test['inadimplente'] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os dados de treino processado\n",
    "train.to_csv('../data/processed/train.csv', \n",
    "             sep=',', index=False)\n",
    "\n",
    "# Salvando os dados de teste (Neste caso, será chamado \n",
    "# como dev, pra não ter engano com os dados de teste final)\n",
    "test.to_csv('../data/processed/dev.csv', \n",
    "            sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
